{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "from nnbma.networks import DenselyConnected, PolynomialNetwork, FullyConnected\n",
    "from nnbma.dataset import RegressionDataset, MaskDataset\n",
    "from nnbma.learning import learning_procedure, LearningParameters, MaskedMSELoss, LinearBatchScheduler, BatchScheduler\n",
    "\n",
    "from nnbma.layers import PolynomialExpansion\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def error_factor (y_hat: np.ndarray, y: np.ndarray) :\n",
    "     ef_vector=np.exp(np.log(10)*np.abs(y_hat - y))\n",
    "     return (np.percentile(ef_vector,99),np.mean(ef_vector))\n",
    "\n",
    "def metric(y_hat: np.ndarray, y: np.ndarray):\n",
    "    return np.mean((y_hat - y) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder in which the trained neural net will be saved\n",
    "output_root = \"../data/models\"\n",
    "\n",
    "# folder containing the dataset of evaluations of the astrophysical simulator\n",
    "data_dir = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3769ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv(f\"{data_dir}/dataset_train_test.csv\", index_col=0)\n",
    "\n",
    "idx = np.arange(len(df_dataset))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_frac = 0.7\n",
    "idx_max_train = int(0.7 * len(df_dataset))\n",
    "\n",
    "df_train = df_dataset.iloc[idx[:idx_max_train], :] * 1\n",
    "df_test = df_dataset.iloc[idx[idx_max_train:], :] * 1\n",
    "\n",
    "X_train = np.log10(df_train.iloc[:, :3].values)\n",
    "Y_train = np.log10(df_train.iloc[:, 3:].values)\n",
    "X_test = np.log10(df_test.iloc[:, :3].values)\n",
    "Y_test = np.log10(df_test.iloc[:, 3:].values)\n",
    "\n",
    "X_labels = list(df_train.columns)[:3]\n",
    "Y_labels = list(df_train.columns)[3:]\n",
    "\n",
    "X_labels, Y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991eda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8447875",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704100ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Normalisation des donn√©es entre 0 et 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "train_dataset = RegressionDataset(X_train, Y_train)\n",
    "test_dataset = RegressionDataset(X_test, Y_test)\n",
    "print(f\"Number of training entries: {X_train.shape[0]:,}\") # 154\n",
    "print(f\"Number of testing entries: {X_test.shape[0]:,}\") #20 #49\n",
    "\n",
    "n_layers = 4 # controls the number of layers in your neural network\n",
    "growing_factor = 0.5\n",
    "\n",
    "activation = nn.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0862f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1] * 1 # input vector size\n",
    "\n",
    "# -------------Polynomial Expansion\n",
    "order = 3  # no larger, otherwise will overfit\n",
    "n_poly = PolynomialExpansion.expanded_features(order, n_features)\n",
    "\n",
    "# -------------Densely connected network\n",
    "subnet = DenselyConnected(n_poly, L, n_layers, growing_factor, activation, outputs_names=Y_labels)\n",
    "\n",
    "# -------------Combining both\n",
    "net = PolynomialNetwork(\n",
    "    n_features,\n",
    "    order,\n",
    "    subnet,\n",
    "    inputs_names=X_labels,\n",
    "    outputs_names=Y_labels\n",
    ")\n",
    "\n",
    "net.poly.update_standardization(x=train_dataset.x, reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the neural network architecture\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff87f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the number of parameters to train in the neural network\n",
    "net.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5091fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = len(df_train)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.AdamW(net.parameters(), learning_rate)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=20, factor=0.9\n",
    ")\n",
    "\n",
    "learning_params = LearningParameters(\n",
    "    loss, epochs, batch_size, optimizer, scheduler\n",
    ")\n",
    "\n",
    "results = learning_procedure(\n",
    "    net,\n",
    "    (train_dataset, test_dataset),\n",
    "    learning_params,\n",
    "    val_frac=None,\n",
    ")\n",
    "\n",
    "print(f\"Loss over training set: {metric(net(X_train), Y_train):.2e}\")\n",
    "print(f\"Loss over testing set: {metric(net(X_test), Y_test):.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1491710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained neural network\n",
    "# For a definition of the error factor, see the nnbma paper (https://www.aanda.org/articles/aa/abs/2023/10/aa47074-23/aa47074-23.html), equation 6.\n",
    "\n",
    "# for train and test, two values are shown:\n",
    "# the first is the 99th percentile, ie, a robust estimation of the max\n",
    "# the second is the mean\n",
    "print(f\"Error Factor over training set: {error_factor(net(X_train), Y_train)}\")\n",
    "print(f\"Error Factor over testing set: {error_factor(net(X_test), Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f254d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_first = 20\n",
    "\n",
    "plt.figure(figsize=(1.2 * 6.4, 0.6 * 4.8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(results[\"train_loss\"][skip_first:],\"--\",label=\"Train loss\")\n",
    "plt.semilogy(results[\"val_loss\"][skip_first:], label=\"Test loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(f\"loss evolution (skipping the first {skip_first} iterations)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(results[\"lr\"][skip_first:],\"--\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"learning rate evolution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"model\" # name of the folder in which the neural network is saved\n",
    "net.save(name, output_root)\n",
    "\n",
    "import pickle\n",
    "with open(f\"{output_root}/{name}/scaler.pickle\", 'wb') as handle:\n",
    "    pickle.dump(scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d578a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
